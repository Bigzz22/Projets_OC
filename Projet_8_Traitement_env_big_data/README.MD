# â˜ï¸ Traitement Big Data sur le Cloud â€” Projet Fruits!

## ğŸ“Œ Contexte du projet
La start-up **Fruits!** est une jeune entreprise innovante en **AgriTech**.  
Son objectif est de dÃ©velopper des **solutions intelligentes pour la rÃ©colte des fruits** tout en prÃ©servant la biodiversitÃ©.

Dans un premier temps, lâ€™entreprise souhaite se faire connaÃ®tre via une **application mobile** qui permettrait Ã  un utilisateur de **prendre une photo dâ€™un fruit** et dâ€™obtenir automatiquement des informations sur celui-ci.  
Cette application servira Ã©galement Ã  prÃ©parer la **premiÃ¨re version du moteur de classification dâ€™images**.

Pour supporter les futures Ã©volutions et la croissance du volume de donnÃ©es, la start-up souhaite mettre en place une **architecture Big Data scalable sur le cloud AWS**.

---

## ğŸ¯ Objectifs du projet
- Mettre en place une **chaÃ®ne de traitement Big Data** robuste et Ã©volutive.
- CrÃ©er et configurer une **infrastructure AWS EMR** pour traiter un grand volume dâ€™images.
- DÃ©velopper un script **PySpark** pour prÃ©parer les donnÃ©es et optimiser les performances.
- IntÃ©grer :
    1. Le **broadcast des poids du modÃ¨le TensorFlow** sur lâ€™ensemble des nÅ“uds du cluster.
    2. Une **rÃ©duction de dimension PCA** en PySpark pour accÃ©lÃ©rer les traitements.
- Garantir la **conformitÃ© RGPD** en configurant les serveurs dans lâ€™Union EuropÃ©enne.
- Minimiser les **coÃ»ts liÃ©s Ã  AWS** en optimisant lâ€™utilisation de lâ€™instance EMR.

---

## ğŸ“‚ DonnÃ©es utilisÃ©es
- **Source :** [Fruit Images Dataset](https://www.kaggle.com/moltean/fruits)
- **Taille :** ~44 000 images
- **Nombre de classes :** 131 types de fruits
---

## ğŸ§  Approche mÃ©thodologique

### **1. Architecture Big Data**
- Mise en place dâ€™une **infrastructure AWS EMR** :
    - **Amazon S3** : stockage des images et rÃ©sultats.
    - **Amazon EMR** : traitement distribuÃ© via PySpark.
    - **AWS IAM** : gestion des permissions.
    - **Databricks** *(optionnel)* : alternative pour les traitements avancÃ©s.

---

### **2. Traitements en PySpark**
#### **PrÃ©traitement des images :**
- Chargement des donnÃ©es depuis **Amazon S3**.
- Redimensionnement et normalisation des images.
- Encodage des labels.

#### **Broadcast des poids TensorFlow :**
- Diffusion des **poids du modÃ¨le prÃ©-entraÃ®nÃ©** sur les nÅ“uds du cluster pour optimiser lâ€™infÃ©rence.
- AmÃ©lioration significative des performances lors des prÃ©dictions distribuÃ©es.

#### **RÃ©duction de dimension (PCA) :**
- Utilisation de la **librairie MLlib** de PySpark.
- RÃ©duction de la taille des vecteurs dâ€™images pour :
    - Diminuer le temps de calcul.
    - Optimiser la mÃ©moire sur les nÅ“uds.

---

### **3. Optimisation des coÃ»ts AWS**
- DÃ©veloppement et tests locaux â†’ **serveur local** pour limiter les coÃ»ts.
- Utilisation ponctuelle de lâ€™instance **AWS EMR** uniquement pour les phases critiques.
- Limitation des coÃ»ts totaux Ã  **moins de 10 â‚¬**.

---

## ğŸ“Š Livrables
- **Script PySpark principal** â†’ prÃ©traitement des images et PCA.
- **Script TensorFlow** â†’ broadcast des poids sur le cluster.
- **Documentation technique** â†’ dÃ©ploiement de lâ€™infrastructure EMR.
- **DÃ©monstration** â†’ traitement Big Data opÃ©rationnel sur AWS.

---

## âš™ï¸ Technologies utilisÃ©es
- **Langage :** Python 3.10
- **Framework Big Data :**
    - **PySpark** â†’ traitement distribuÃ©.
    - **MLlib** â†’ PCA et machine learning distribuÃ©.
- **Deep Learning :**
    - **TensorFlow / Keras** â†’ gestion des poids du modÃ¨le.
- **Cloud :**
    - **AWS EMR** â†’ cluster Big Data.
    - **AWS S3** â†’ stockage des donnÃ©es.
    - **AWS IAM** â†’ gestion des droits dâ€™accÃ¨s.
    - **Databricks** *(optionnel)* â†’ alternative pour le dÃ©veloppement collaboratif.
- **Outils :**
    - Jupyter Notebook
    - Git / GitHub

---

## ğŸ‘¤ Auteur
**Benjamin Bigot**  
ğŸ“§ [benjamin.bigot22@gmail.com](mailto:benjamin.bigot22@gmail.com)  
ğŸ”— [LinkedIn](https://www.linkedin.com/in/benjamin-bigot-69b0581a3/)

---
