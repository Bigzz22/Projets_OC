{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10405374,"sourceType":"datasetVersion","datasetId":6447978},{"sourceId":218159052,"sourceType":"kernelVersion"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport sqlite3\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import adjusted_rand_score\nimport datetime\nimport matplotlib.pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:36.961614Z","iopub.execute_input":"2025-01-23T09:07:36.961978Z","iopub.status.idle":"2025-01-23T09:07:40.420059Z","shell.execute_reply.started":"2025-01-23T09:07:36.961950Z","shell.execute_reply":"2025-01-23T09:07:40.418843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"rfm_data = pd.read_csv('/kaggle/input/bigot-benjamin-2-notebook-exploration-012025/customers_features.csv')\n\ndisplay(rfm_data.head())\ndisplay(rfm_data.info())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:40.421651Z","iopub.execute_input":"2025-01-23T09:07:40.422274Z","iopub.status.idle":"2025-01-23T09:07:40.720047Z","shell.execute_reply.started":"2025-01-23T09:07:40.422234Z","shell.execute_reply":"2025-01-23T09:07:40.719128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"db_path = \"/kaggle/input/olist-database/olist.db\"\n\nconn = sqlite3.connect(db_path)\n\ntables_query = \"SELECT name FROM sqlite_master WHERE type='table';\"\ntables = pd.read_sql_query(tables_query, conn)\ndisplay(\"Tables disponibles dans la base de données :\", tables)\n\ncustomers_data = pd.read_sql_query(\"SELECT * FROM customers\", conn)\norders_data = pd.read_sql_query(\"SELECT * FROM orders\", conn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:40.722224Z","iopub.execute_input":"2025-01-23T09:07:40.722513Z","iopub.status.idle":"2025-01-23T09:07:41.879565Z","shell.execute_reply.started":"2025-01-23T09:07:40.722488Z","shell.execute_reply":"2025-01-23T09:07:41.878580Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_features_for_date(conn, date_limit):\n    \"\"\"\n    Génère les statistiques RFM et la moyenne des scores des avis pour une date limite donnée \n    en filtrant les commandes dans la base SQLite.\n    \"\"\"\n    query = f\"\"\"\n    SELECT\n        customers.customer_id,\n        MAX(orders.order_purchase_timestamp) AS last_order_date,\n        COUNT(orders.order_id) AS frequency,\n        SUM(order_pymts.payment_value) AS monetary,\n        AVG(order_reviews.review_score) AS avg_review_score\n    FROM customers\n    JOIN orders ON customers.customer_id = orders.customer_id\n    JOIN order_pymts ON orders.order_id = order_pymts.order_id\n    LEFT JOIN order_reviews ON orders.order_id = order_reviews.order_id\n    WHERE orders.order_purchase_timestamp <= '{date_limit}'\n    GROUP BY customers.customer_id\n    \"\"\"\n    rfm = pd.read_sql_query(query, conn)\n    \n    # Convertir la date de la dernière commande en \"Recency\" (jours depuis la dernière commande)\n    date_limit_dt = pd.to_datetime(date_limit)\n    rfm['last_order_date'] = pd.to_datetime(rfm['last_order_date'])\n    rfm['recency'] = (date_limit_dt - rfm['last_order_date']).dt.days\n\n    # Garder uniquement les colonnes RFM et la moyenne des scores d'avis\n    rfm = rfm[['recency', 'frequency', 'monetary', 'avg_review_score']]\n    \n    return rfm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:41.880969Z","iopub.execute_input":"2025-01-23T09:07:41.881289Z","iopub.status.idle":"2025-01-23T09:07:41.887374Z","shell.execute_reply.started":"2025-01-23T09:07:41.881263Z","shell.execute_reply":"2025-01-23T09:07:41.886195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"query = \"\"\"\nSELECT \n    MIN(order_purchase_timestamp) AS first_order_date,\n    MAX(order_purchase_timestamp) AS last_order_date\nFROM orders;\n\"\"\"\n\ndates = pd.read_sql_query(query, conn)\ndisplay(dates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:41.888362Z","iopub.execute_input":"2025-01-23T09:07:41.888687Z","iopub.status.idle":"2025-01-23T09:07:42.158166Z","shell.execute_reply.started":"2025-01-23T09:07:41.888650Z","shell.execute_reply":"2025-01-23T09:07:42.157256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Définir la date de départ T0\nstart_date = \"2018-04-17\"\n\n# Générer les statistiques RFM pour T0\nrfm_F0 = create_features_for_date(conn, start_date)\nrfm_F0['avg_review_score'].fillna(rfm_F0['avg_review_score'].mean(), inplace=True)\n\n# Standardiser les données RFM\nscaler_M0 = StandardScaler().fit(rfm_F0[['recency', 'frequency', 'monetary', 'avg_review_score']])\nrfm_F0_scaled = scaler_M0.transform(rfm_F0[['recency', 'frequency', 'monetary', 'avg_review_score']])\n\n# Entraîner le modèle KMeans initial (M0)\nkmeans_M0 = KMeans(n_clusters=5, random_state=42).fit(rfm_F0_scaled)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:42.159221Z","iopub.execute_input":"2025-01-23T09:07:42.159605Z","iopub.status.idle":"2025-01-23T09:07:44.412689Z","shell.execute_reply.started":"2025-01-23T09:07:42.159571Z","shell.execute_reply":"2025-01-23T09:07:44.411836Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Définir la plage temporelle pour les simulations\nend_date = \"2018-10-17\"\ndate_interval = datetime.timedelta(days=7)\n\ncurrent_date = datetime.datetime.strptime(start_date, \"%Y-%m-%d\")\nend_date_dt = datetime.datetime.strptime(end_date, \"%Y-%m-%d\")\nari_scores = []\n\n# Itérer sur chaque intervalle de temps (1 semaine)\nwhile current_date <= end_date_dt:\n    print(f\"Calcul des clusters pour la date {current_date.strftime('%Y-%m-%d')}\")\n\n    # Générer les statistiques RFM + avg_review_score pour la date actuelle\n    rfm_Fi = create_features_for_date(conn, current_date.strftime(\"%Y-%m-%d\"))\n\n    # Vérification et traitement des valeurs manquantes pour avg_review_score\n    if 'avg_review_score' in rfm_Fi.columns:\n        rfm_Fi['avg_review_score'].fillna(rfm_Fi['avg_review_score'].mean(), inplace=True)\n    else:\n        rfm_Fi['avg_review_score'] = rfm_Fi['avg_review_score'].mean()  # Gestion si la colonne manque\n\n    # Standardiser les données avec le scaler initial M0\n    rfm_Fi_scaled = scaler_M0.transform(rfm_Fi[['recency', 'frequency', 'monetary', 'avg_review_score']])\n\n    # Prédiction avec le modèle initial M0\n    Ci_init = kmeans_M0.predict(rfm_Fi_scaled)\n\n    # Entraîner un nouveau modèle KMeans sur les données actuelles\n    kmeans_M1 = KMeans(n_clusters=5, random_state=42).fit(rfm_Fi_scaled)\n    Ci_new = kmeans_M1.labels_\n\n    # Calculer l'ARI entre les clusters initiaux (M0) et les clusters nouvellement entraînés (M1)\n    ari = adjusted_rand_score(Ci_init, Ci_new)\n    ari_scores.append((current_date.strftime(\"%Y-%m-%d\"), ari))\n    print(f\"Date : {current_date.strftime('%Y-%m-%d')} | ARI : {ari:.4f}\")\n\n    # Avancer à la semaine suivante\n    current_date += date_interval\n\n# Afficher les résultats de l'ARI\nari_df = pd.DataFrame(ari_scores, columns=[\"Date\", \"ARI\"])\nplt.figure(figsize=(12, 6))\nplt.plot(ari_df[\"Date\"], ari_df[\"ARI\"], marker=\"o\", label=\"ARI\")\nplt.axhline(y=0.8, color=\"r\", linestyle=\"--\", label=\"Seuil ARI = 0.8\")\nplt.xticks(rotation=45)\nplt.xlabel(\"Date\")\nplt.ylabel(\"ARI\")\nplt.title(\"Évolution de l'ARI dans le temps\")\nplt.legend()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:07:44.413361Z","iopub.execute_input":"2025-01-23T09:07:44.413671Z","iopub.status.idle":"2025-01-23T09:10:19.416637Z","shell.execute_reply.started":"2025-01-23T09:07:44.413645Z","shell.execute_reply":"2025-01-23T09:10:19.415422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dates, scores = zip(*ari_scores)\n\n# Tracer l'évolution de l'ARI\nplt.figure(figsize=(10, 6))\nplt.plot(dates, scores, marker='o')\nplt.axhline(0.8, color='r', linestyle='--', label=\"Seuil ARI = 0.8\")\nplt.title(\"Évolution de l'ARI dans le temps\")\nplt.xlabel(\"Date\")\nplt.ylabel(\"ARI\")\nplt.xticks(rotation=90)\nplt.legend()\nplt.grid()\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T09:10:19.419158Z","iopub.execute_input":"2025-01-23T09:10:19.420039Z","iopub.status.idle":"2025-01-23T09:10:20.128763Z","shell.execute_reply.started":"2025-01-23T09:10:19.419991Z","shell.execute_reply":"2025-01-23T09:10:20.127487Z"}},"outputs":[],"execution_count":null}]}